<p> <html>   <head>     <meta name="viewport" content="width=device-width, initial-scale=1.0">     <style>       * {         box-sizing: border-box;       }       body {         width: 30em;         margin: auto;         font-size: 22px;         line-height: 1.5em;         overflow-wrap: break-word;         word-wrap: break-word;         hyphens: auto;       }       @media (max-width: 704px) {         body {           padding: 0 1em;           width: 100%;         }       }     </style>     <title>Odrzutowiec Blog</title>   </head>   <body></p>

<h3>Sat  1 Aug 23:51:00 CEST 2020</h3>

<p> I noticed that deleting all content of a file and then executing 'u' undo command generates another db error. After short investigation I found append() to be the reason. Nvi "loggs" all changes to the open text document to be used later as history that can be traversed with "u" and ".". The append() function interanlly operates on the database. For some reason after deleting all contents in the file and then pressing "u" I get following error: "Error: unable to insert at line 0: BDB0063 DB_BUFFER_SMALL: User memory too small for return value". I suspect like with the previous bug I solved it's related to changing the berkeley database version from 3 to 5. I downloaded the official docmentation, and it's pretty extensive. I've read opinions that BDB is fairly easy in usage but it may be too much for me at the moment. I want to actually understand the problem and solve it properly and it will require of me to understand how BDB works and how to use it. I'm afraid it maybe be too much for me right now so I decided to temporarly go back to KnR untill I feel more confident with C. </p>

<p> Also I just noticed the ampersand doesn't work in my blog tech. My awk script think's I'm trying to use a variable.</p>

<h3>Sat 25 Jul 14:40:36 CEST 2020</h3>

<p> I noticed today that my server is having higher amount of bandwidth usage then it should. Pretty much noone knows about it so I'd expect zero activity. but in july there was almost 0.5GB of data sent by my server. I checked out the nginx logs and it looks like I am being constantly scanned for vulnerabilities. That's pretty scary. Who knows about it? And why do they do this? I check few IPs: russia, the netherlands, hong kong, they are all over the place, obviously not using their laptops and networks directly. I have nothing of value on my server, i suspect this may be an amtomated scan. I'm just not sure where they learned about my domain. Anyway for now I just limited the requests to save on the server bandwith.</p>

<h3>Tue 21 Jul 22:34:35 CEST 2020</h3>

<p> I fixed the db problem. It was simply a change in the db_open api in db5. It needs now DB_CREATE flag. Easy enough. After fixing this I discovered that the "catalog" code (probably unix name or name convention for internationalization) it was trying to load a file based on the LANG env var which obviously doesn't exist because I have removed the catalog directory completely. I disabled the catalog file loading with early return 1 in the loading function. I also left a TODO comment there to remember I need to clean it up since I won't be using it at all. If you are usig vi-like program you can speak english, let's be reasonable.</p>

<h3>Sat  4 Jul 13:27:02 CEST 2020</h3>

<p> I updated the <a href="">readme file in vip repo</a> recently, including a section with featrure ideas. Next day I randomly stumbled upon <a href="https://opensource.apple.com/source/vi/vi-7/nvi/docs/features.auto.html">Apple's notes on features ideas for nvi</a>. That's a good source of inspirations for features. In general I'm surprised that apple has nvi source code and it my come in useful in more ways then one.</p>

<h3>Fri  3 Jul 00:14:54 CEST 2020</h3>

<p> I've finally finished removing all clutter from the vip's source code. From the original 612 files there are now only 172 files left. A whole lot less files to maintain and understand.</p>

<p> My recent effort in migrating the codebase from inhouse regexp to the TRE library served me well as hoped. I started making changes in the actual code and got more confident with GDB and debugging. I feel I'm now ready to starting introducing new features. </p>

<p> Before that however, there are still few bugs to iron out which appeard after all that clutter removal. Most noticable of which is the strange error about database each time I close vip. "BDB0635 DB_CREATE must be specified to create databases." it utters unashamed each time for goodbye. I suspect that's because Vip was using db3 before and now I made it use system's version which on my system is db5. Not a big deal, vip functions most of the time normaly. Still that's the first bug to fix.</p>

<h3>Tue 30 Jun 23:18:48 CEST 2020</h3>

<p> Grand success! After few days of banging my head on the widechar and regexp search problem I decided to test it in isolation. I created a simple program with few lines of c built it with gcc myself - just a new, super small project to test things out. I quickly realised that TRE supports widechar charters but not via standard regcomp() and regexec() api, it has regwcomp() and regwexec()! That was the key! I was feeding widecharacter strings to normal regex functions and they were getting confused. So I have now a functioning widechar version of vi using TRE for regexes!</p>

<p> There is still the problem with missing support for REG_STARTEND which produces false postives in some lines and matches only the first occurance in the line (so "n" command doesn't jump to the next occurance in the same line) but I can emulate it with the idea I was talking about in the previous post. It's somewhat annoying but I can see now that's almost back to be 100% functioning.</p>

<h3>Wed 24 Jun 23:33:16 CEST 2020</h3>

<p> I managed to replace the glibc regex library with <a href="https://github.com/laurikari/tre">TRE</a>. There was only a single issue with compilation after replacing the library. The codebase is using non-POSIX REG_STARTEND regexec() flag. For now I just removed that flag. Other then that everything compiled flawlessly including the --enable-widechar compilation option.</p>

<p> The executable seems to function normally. I can enter and see correct wide characters including ą and ł. However the search feature seems to be off. It seems to be matching only the first word in a line. I suspect it has something to do with that REG_STARTEND I removed.</p>

<p> From what I could find out f_search() calls db_get() to load a line of text from the opened text file. As far as I can see db_get() copies the value of the line onto one of the arguemnts it receives without cleaning this argument first so lines often look like current line was just pasted on top of the last line. I presume that was done in the name of performance and is relaying on that REG_STARTEND flag.</p>

<p> I am not entirely sure but I suspect if I can emulate the REG_STARTEND behaviour I can fix the search but it's a gamble - I am not 100% sure what is actually going on. Anyway the "cleverest" idea I had on how to emulate REG_STARTEND was to just clean the line variable so that regexec() is operating on a clean line each time.</p>

<h3>Tue 23 Jun 20:19:02 CEST 2020</h3>

<p> Yesterday it was really late when I was investigating f_search(). I realised that I saw in GDB a value for a string that was presented by GDB as L"some string" because it was a wide char string. It seems that nvi keeps all strings as wide characters when --enable-widechar compilation options is used. </p>

<p> I now think that f_search() or re_compile() or re_conv() or any other function is not the root cause of the problem. The problem is that all strings are wide, as in each character takes 16 bits while the regex expects 8 bits only, there is nothing I can do about it other then disable widechars therefor changing the memory alignment back to 8 bits per character like regex expects or change the regex library to one that supports wide character strings. Well I could also try to "flatten" the wide strings to normal strings just when they are fed to the regexec() function, but those kind of hacky solutions often tax you increasingly the further you go.</p>

<p> I'm not sure if disabling the widechars is a viable options. Theoretically I could disable the widechars and make the entire system operate on 8 bit strings while enabling widechar curses library so that it can still render wide characters correctly in the terminal. That seems plausable, however I'm not sure how will the system behave when moving cusor around a wide character. Assuming that this idea would work, lets say we have a string "hello Micha|ł" where | is the cursor. If I have 8 bit string and 16 bit curses library, what happens if I move the cursor one character to the right now? Have I moved 8 bit or 16 bit? And if I moved 8 bit is my cursor "inside" the "ł" from the perspective of curses library? That could prove problematic. However if this would just work, it would be the simplest solution, so it's still tempting to investigate it.</p>

<p> The other option is to replace the libc's regex library with some other "mostly compatible" library which supports wide characters. I say "mostly compatible" because I found out yesterday that nvi does some light processing on the regex pattern before compiling it in re_conv(). So whatever library I choose should have regex syntax similiar enough so that I don't need to change re_conv() too much. I found following candidates:</p>

<ul>
<li>PCRE - perl's regex library, widly popular library and syntax, mostly superset for libc's regex syntax</li>
<li>TRE - <a href="https://github.com/martanne/vis">vis editor</a> is using that under the hood</li>
<li>RE2 - a regex library from google, seems quite popular as well</li>
<li>Plan9's regexp - I heard good things about regexes in Plan9</li>
</ul>

<p> Also I noticed that TRE for Vis is optional and when not used Vis uses <regex.h> I wonder how they solved it. I heard that Vis uses musl insatead of glibc. I just checked and musl's regexp is based on TRE, so it's possible that vis has widechar support either way because it uses directly or indirectly TRE.</p>

<h3>Tue 23 Jun 00:12:27 CEST 2020</h3>

<p> It seems like the search results in random positions even when there is no wide characters in searched file. Anyway I briefly checked out f_search(), interanlly executes regexec(). From what I found regexec does not support wide chars so that's potentially the issue but rather unlikely due to the symptopm I mentioned above. But before it calls regexec() it does a bunch of initalisation work: it calls search_init() which calles re_compile() which calls re_conv(). Apparently nvi translates for "vi regexp" to the POSIX regexp. I actually thought vi used POSIX regex syntax directly. And it pretty much does, this re_conv() function just supports the the magic characters and \<ptrn\> literal patterns (not sure what are those patterns atm).</p>

<h3>Sun 21 Jun 23:49:08 CEST 2020</h3>

<p> v_exaddr() eventuall calls f_search() too. Well not directly, v_exaddr() actually calls ex_range() which calls ex_line() which calls f_search(). Point is, all roads lead to f_search. I think my next step will be to investigate how f_search actually works and if it's broken with compile flag --enabled-widechar.</p>

<p> I figured out the above using GDB. GDB is kind of a complex program but it does have some really nice quality of life features built in which allow me to use it without first reading the extensive info gdb manual. The help command is amaizing it lets me pretty much figure things out one the go.</p>

<p> Oh and I updated my homepage, I refreshed and used my old experimental project with react rendering 3D html billbords via css transformations using three-js for 3d perspective calculations. It's quite fun I can make gifs and text and emojis and everything else html can do in 3D spin around. I'm thinking I should capitalize on this technology and make my real homepage based on that. It's visually quite impressive for uninitated and technically interesting since it intentionally avoids webgl (thus can exploit all rendering capacities of standard html browser renderer).</p>

<h3>Sat 20 Jun 14:30:53 CEST 2020</h3>

<p> I finally decided to start hosting my own website. An idea I was toying with for decade and a half. Turns out system administration is a whole lot easier when you poses fundamental competence with unix-like shell.</p>

<ul>
<li><a href="https://michalradecki.com/blog.html">https://michalradecki.com/blog.html</a> is the new home for my blog.</li>
<li>For the time being I'll still support <a href="https://odrzutowiec.github.io/blog/">https://odrzutowiec.github.io/blog/</a> but I think I'll drop it eventually.</li>
</ul>

<p> Since we are nowhere near the subject I want to take this oportunity to remind myself of the following distinction. Why not, my blog, my rules.</p>

<ul>
<li>"command line" - Is a way to describe computer interface which operates only on text entered commands</li>
<li>"shell" - Is a part of unix architecture for command line</li>
<li>"terminal" - Those were old computer devices eralier models reassembled typewriters, later models had CRT screens</li>
<li>"terminal emulator" - Is computer software emulating a terminal device connected to a shell</li>
</ul>

<h3>Wed 17 Jun 21:52:38 CEST 2020</h3>

<p> I noticed that the same searching bug happens in both vi and ex modes, if the authors of nvi had any kind of common sense there is probably a piece of code uses by both vi and ex that performs the actual search. Opensource developers are generally really skilled so I think it's safe to assume that.</p>

<p> I noticed in that vi actually uses ex's address routines for its search feature. All functions in /vi/v_search.c eventually directly or indirectly call v_exaddr(). I'm pretty sure what I am looking for is not in the /vi/ directory.</p>

<p> Not all of the /vi/v_search.c functions actually lead to v_exaddr(). Some lead to f_search() and b_search(), those two are defined in /common/search.c that's another potential candidate.</p>

<h3>Sat 13 Jun 23:59:45 CEST 2020</h3>

<p> Removing /regex is more dificult then I hoped. The autoconf script has --disable-re flag which basically makes the build ignore all code in /regex and link to system's regex.h instead which is great. However after it builds without too much compaining (single use of one non-standard flag REG_NOSPEC) the resulting binary behaves strange. Ctrl+a command results in "RE error: Invalid character class name". </p>

<p> But that's not all, the biggest problem is when I use another autoconf script flag --enable-widechar. When I don't use that option I can't type in polish characters example for "polish a": "ą". And if I do use --enable-widechar I can type "polish a" normally "ą", but the / search feature yilds random results it matches arbitrary places in the file.</p>

<p> I don't exactly nderstand why the regex library bundled with nvi source works properly and the gnu regex library does not. From what I found out both POSIX's and GNU clib's regcomp() don't support widecharacter strings. I couldn't find any information on BSD's regcomp(). Does it support widechars? If it doesn't what makes it work properly while gnu's doesn't?</p>

<p> I don't really know what I am talking about or how characters are really actually handled in C. I know that standard ASCII and POSIX characters are 8 bit (actually 7 bit, last bit is not used) and therefor can encode english alphanumerics and few extra symbols. UTF8 is what's called "variable length encoding" which means that most common characters are encoded in 1 byte like ASCII less common characters in 2 bytes and so on up to 4 bytes. There are also "widechar" strings in C which seems to be a different name for UTF16 which is kind of like UTF8, also "variable length" however it consists of one or two 16 bit codes (as opposed to UTF8's one up to four 8 bit codes). </p>

<h3>Wed 10 Jun 23:10:16 CEST 2020</h3>

<p> My <a href="https://github.com/odrzutowiec/vip">nvi fork project</a> is making steady progress. I decided to name it VIP, I'm quite enjoying all the potential expansions of the acronym. Vi by Pyzozord (my IRC nickname), Very Important Program, VI with Plugins, VI Perfected. The possibilites are endless.</p>

<p> Anyway I managed to remove even more stuff: catalog - responsible for translations, clib - no need to support environemnts who don't have full c library, db - no need to maintain source for that, instead I'm using now libdb and ip/ipc - no need to worry about inter process communication for now, I have a specyfic idea for how I want the plugin system to work.</p>

<p> Hopefully I can remove regexp, ideally I don't want to maintain regular expression engine and just link statically a regexp library available on the system.</p>

<p> Can't wait to the moment I'll start writing features for this thing. Not sure what the first feature should be. Something helloworld-y, something just to get me started. Maybe just modification for the visual bell, the full screen flash is quite obtrusive.</p>

<p> In fact I'm actually writing this post in the latest build of vip, there is virtually no difference what so ever comparing to the normal nvi.</p>

<p> After vip will be usable enough, the next step will be to make my own terminal emulator. I want something extremly simple. But I do want media playback in the background. I want my terminal to be able to display images and videos in the background and adjust solid color overlay so forground text is still readable. I'm eyeballing the <a href="http://st.suckless.org">suckless terminal</a>. It's based on Xorg but maybe I could migrate it to SDL so that I can compile it on mac? It's quite great, really lean code, still well supported and plenty of extra features I can add via code patches.</p>

<p> Writing code in my own code editor inside my own terminal emulator... Finally at peace.</p>

<p> Can't wait for those looks in the eyes of collegues who asked "What terminal are you using?" or "Your Vi looks quite strange, how did you do that?".</p>

<h3>Sun 24 May 15:52:27 CEST 2020</h3>

<p> Since firday I've been reading the <a href="https://repo.or.cz/nvi.git">nvi repo</a>. I decided writing my own editor in c is the best way to refresh my c-fu. It's been quite educative and definetly a history lesson of open source software development. I've cloned it and started removing features I'm not interested in like perl/tcl support or gtk/motif versions. </p>

<p> I'm very excited. Vim is too much. It took me a decade to get familiar with it and I still don't know more then a half of it. Ed is too simplistic, support for autoindentation is a must in 2020, same with tab/space indentaion conversion. Vi is almost perfect, but I still miss some quiality of life features from vim. I think the perfect editor for me is somewhere between vi and vim. </p>

<p> I also have my own ideas on how to improve it. </p>

<p> I want to implement Plan9's Structural Regular Expressions like they did in <a href="https://github.com/martanne/vis">vis</a>. Also I had some ideas about a new mode for vi editor which also operates on objects and motions but they are ast objects and motions instead of word objects and motions. And finally I'd like to have scripting support for any and all languages. </p>

<p> I don't want to have built in interpreter for perl or lua or nodejs. Instead I'd like to leverage posix process communication (maybe pipes?) so that users can write scripts in any and all languages they like extremly easily. If you want to add a new word object you can do it in a simple php program which just uses standard input and output to communicate with VIP. Or any other language for that matter. Or add entirly new editing mode. I want the scripting to be based on standard basic posix features, extremly easy to implement (so that a developer with less then 6 months of experience could extend VIP however they want) and extremly powerful (so that scripting can change virtually any aspect of how Vip works). Lofty dreams I know.</p>

<p> <a href="https://github.com/odrzutowiec/vip">https://github.com/odrzutowiec/vip</a></p>

<h3>Mon  4 May 12:18:35 CEST 2020</h3>

<p> My interest are in few things and those things seem to naturally intertwine and connect with each other in a complex, folded many times over manner. Every time I learn something new	on the edge of my area of interest I discover entirly new locus of meaning which connects in new, surprising and complex ways with the existing body of knoweledge making the entire model even more convoluted. I developed an interest in systems via programming. There are many differnt systems at different levels. On other such system is social dynamics in professional context. And generally in any context. Recently I came across the Gervais Principle. It's an amazing, engineering model of social dynamics of comercial organisations. </p>

<p> <a href="https://www.ribbonfarm.com/the-gervais-principle/">https://www.ribbonfarm.com/the-gervais-principle/</a></p>

<p> I am in shock. It made me understand so many before unexplainable evenets I have experienced. I was intuitively half aware of some small partion of this model, but having it all layed out like that clearly and comprehensively opens my eyes. At first I was furious. I felt cheated like a complete idiot. I was the Clueless. I have now wide open manuvering field. I just need to decide what I want. (This last part may be more difficult then it sounds)</p>

<h4>Tue Mar  3 21:42:30 CET 2020</h4>

<p> I've been spending some time exploring OpenBSD, pretty cool stuff. I am thinking about migrating to OpenBSD full time. I think I'm naturally aligned with the philosphy behind it. From my experience a well fit symbiosis like this brings unexpected desirable results. Things just click together in places one wouldn't expect.</p>

<p> I've been also migrating from Vim to Vi. I had a brief episode with Ed but quickly discovered I do need a little more then that (auto ident was the thing that pushed me over the edge). So now I'm on Ex and the Vi. I first started with Ex-Vi (the traditional ex and vi) but today I moved on to the little cleaned up and just a bit bigger Nvi. Nvi is fully "bug-to-bug" compatible with ex-vi, but has got few extra features. It's also the default version of vi on BSD systems including OpenBSD.</p>

<p> Lastly I made more progress with my genetic algorithm. I further improved the graph visualisation. First of all I ordered each individual in a generation from highest to lowest fitness. When the graph displayes all generations it's now easily visible how one outstanding individual in generation X breeds into 90% of the population X+3. This help me understand <em>why</em> is my algorithm not finishing. I believe that my populations become to monotonous, having mostly identical DNA. I am thinking now about improving the breeding processes from random to a weighted random. Individuals will prefer other individuals with fitnessess that complement theirs as breeding partners. This is pretty exciting, it may be the solution! And I haven't even got to counting schemata. I think if I'm lucky enough I may not have to implement counting schemata for breeding preference, very simple difference in fitnesses may be enough!</p>

<h4>Sat Feb 22 15:12:15 CET 2020</h4>

<p> I was finally done with the research for spatial partitioning and decided to share it on <a href="https://www.reddit.com/r/roguelikedev/comments/f4ouh5/infinite_game_worlds_and_spatial_data_structures/">rouglikedev reddit</a>. It got quite popular and sparked some interesting conversations. Anyway I'm a little tired with this subject for the moment and the article was finally done.</p>

<p> I started thinking about new project. And decided to come back to my genetic algorithm week planner. I was maintaining that project for more or less half year without developing any new features. Just cleaning up the code and updating the dependencies from time to time. Today I spent a moment adding a click debug feature displaying information about each clicked individual on the graph. And that lead me to a small breakthrough. The algorithm wasn't performing well because it was selecting random individuals for breeding. My fitness sorting function was incorrect. Fixing the sorting fixed the selection which in turn fixed the breeding and suddenly everything fell into place. Now it's performing quite well. It is still stuck in local maximum after few generations but it is now very close to solving the weekly schedule. I am happy with this. My next step is to start plotting different variables like total generation fitness over time and maybe some other things that would give me more insight and help debug why it's stuck in the local maximum.</p>

<p> Oh I also made the smallest but coolest quality of life improvement to my bash setup.</p>

<p> <code></code><code> function tree() {   find ${@-./*} | sed -E 's:[^/]+/: :g' } </code><code></code></p>

<p> This is my home brew replacement for the popular <code>tree</code> cli tool. I'm working on mac so I don't have it available to me out of the box and I really hate the idea of installing third party tool if I can use the tools available to me already to solve the problem. </p>

<p> Together with the <code>scout</code> (tool giving a birds eye overview of the biggest directories I made few months earlier) and all of POSIX (mostly <code>find</code> and <code>grep</code>) they make great tools at exploring new code bases and directories.</p>

<p> <code></code><code> function scout() {   for F in ${@-./*}; do echo "$(find $F | wc -l) $F"; done | sort -r } </code><code></code></p>

<p> Ugh, I see need to fix my blog markdown parser so it doesn't mess with code blocks or inside html tags.</p>

<h4>Space Partitioning - Sun Feb 16 10:03:46 CET 2020</h4>

<p> I've been thinking a bit more recently about infinite game worlds and roguelike games. I found a very interesting free book http://gameprogrammingpatterns.com/. It has a chapter about spatial partitioning which is exactly what I was interested in. Unfortunately that chapter is very fundamental and does not answer my question. It did give me few ideas though.</p>

<p> My goal would be to have an infinitely big, persistent world. The game would not have to simulate every single agent in the entire world on every game loop tick. That would be silly. It would simulate only the agents within the view of the player. All other agents instead of being simulated separately would be rather kind of reduced to a "heat map of probabilities" in a similar way GTA or SimCity games do with cellular automata layers. But even in that case there would be static objects which don't require processing every tick but do require being remembered separately. For example if I'd kill a deer and then left that area to gather wood for a bonfire, I would expect the deer's corpse to still be there when I return.</p>

<p> I can imagine a simple 1 dimensional array with a list of all objects in the world. Such a list would be really long so I would be able to load only chunks of it at a time. How do I know which chunks to load? I should load only relevant chunks so onces that are near the player or in the player's view.  Well if I care about the chunks of the list of game objects in a spatial sense (only chunks <em>close to</em> the player) than I should assign some spatial information to those chunks (aka index them). All fine so far, lets say our chunks are laid out on a grid of 16x16 "meters" and each chunk can hold any number of objects. Not ideal for very densely populated areas but let's ignore this problem for now and continue.</p>

<p> Knowing chunk's size and x, y coordinates of the chunk I want I can easily calculate the position of that chunk in the file and load it into memory. Great! Eureka! I can go home. But what if usually there will be big number of chunks processed at once? I'd need to do IO file operation for many of the chunks I want to load. Is there any way I could pack and order those chunks in a file to minimize IO operations when reading them? </p>

<p> From a simple calculation we can guestimate how long an average io operation takes on a HDD. Lets assume a 7200 RPM HDD (120 RPS) with average seek time 8ms. RPM stands for "revolutions per minute" or simply rotations per minute. To read data from a spinning disk HDD has to move the head (the needle) to the right position and then wait up to 1 full rotation. Ignoring time for the cpu overhead we can say that 8ms seek + rotational latency (1s / 120rps = ~8ms) is 16ms for a single read. Simply reading a big file in continuous fashion will generate multiple io operations. Naturally seeking to neighbour tracks will be much faster than changing a cylinder and our guestimate is generally really rough. But for our purposes knowing the order of magnitude should be enough. You can read more here https://en.wikipedia.org/wiki/Hard_disk_drive_performance_characteristics.</p>

<p> I looked into few different ideas on how to index and encode the chunks on wikipidia https://en.wikipedia.org/wiki/Spatial_database#Spatial_index and that game programming book http://gameprogrammingpatterns.com/spatial-partition.html.</p>

<p> https://sites.cs.ucsb.edu/~suri/psdir/ASP.pdf</p>

<p> <strong>Binary Trees</strong> While thinking about ways I could encode the coordinates in a file I arrived at Binary Trees. Not exactly a spatial data structure. Rather a fundamental computer data structure. Idea is simple a set of values is recursively divided into two subsets. Left set holds values smaller then the division point, right set holds values bigger then the division point. Only leaf nodes (nodes without children) of the tree hold actual po. There is many different permutations of that idea and there are many different considerations. Balancing the tree is often one of the big concerns.</p>

<p> <strong>B-Trees</strong></p>

<p> After Binary Trees I skipped over the binary heaps, binomail heaps and priority queues. Then I found B-Trees (https://queue.acm.org/detail.cfm?id=1814327). Simply put, B-Trees are a lot like Binary Trees but can have <em>m</em> max children (rather then 2) and are designed such that really large trees can be kept in storage and only part of the tree is loaded to memory at any moment. Similar indexes are paged in and out of memory together. That minimises the amount of memory (and io) operations For some reason I got inspired to check if MySQL uses B-trees, and it does. Then I saw that MySql uses R-Trees for spatial indexes. Then my head started spinning, I'm in over my head.</p>

<p> <strong>Grid</strong></p>

<p> But first Grid. Grid is the simples solution to my problem. Divide the world into equal size chunks with X and Y coordinates. Keep each chunk saved as a separate file is enough. Since this project is educational for me and I want to wet my feet in a bit in algorithms and data structures and the techniques similar to those used in the 3D engines I decided I still want to implement something more complex. To make it more challenging I decided I want my game to also support polygons. In case of grid it's quite easy to just cut the polygons at the chunk edges.</p>

<p> <strong>Space filling curves</strong></p>

<p> Space filling curves like Hilbert Curve are very interest and simple. It would certainly help save the chunks in a file in a more "streamable" fashion since the Hilbert curve makes the file bit stream more chunky and area like instead of having acontinuous horizontal line of the entire world. It would probably decrease amount of io needed to load the right chunks from the memory.</p>

<p> <strong>BSP Trees</strong></p>

<p> Binary Space Partitioning Trees are famous. They were used in the 90s for most of the 3D games, most notably Doom. It recursively subdivides the space into two convex spaces using hyperplanes as partitions.</p>

<p> <strong>Quadtrees</strong></p>

<p> Next are quadtrees. I know quadtrees or more specifically octrees are commonly used in the 3D video game industry. If I'm not mistaken leading occlusion culling software Umbra3D (used by such games as DOOM 2016 or Witcher 3) uses octrees as foundation for their algorithm. My first thought about quadtrees is that they share a lot with the hilbert curve. It seems like a quadtree could be encoded using hilbert curve. Quadtrees are also a special case of a BSP Tree.</p>

<p> <strong>K-d tree</strong></p>

<p> Another binary tree. This one is k-dimensional. It's actually another special case of a BSP Tree. Each leaf of the tree is a point that implicitly splits the space into two so called "half-spaces". K-d trees are used in ray tracing probably because they are very efficient at queries but they are too slow for real time manipulations, building and rebuilding takes too long.</p>

<p> <strong>R-trees</strong></p>

<p> Wikipedia entry on r-trees is promising. They have native support for polygons and were specifically design for large datasets that cannot be kept entirely in memory and have to be paged in and out of ram from disk. seems like r-trees generally have faster lookups and quadtrees are faster to build, interesting trade off. Another interesting fact about r-trees is that they use MBR (minimal bounding rectangles) which means I can have the top level of the tree spanning entire galaxy and immediate next level really small for example 16 square meters. That means no unnecessary subdivisions and index tree branches in a galaxy where only fraction of one percent has been generated.</p>

<p> <strong>Geohash</strong></p>

<p> Geohash approach seems very similar to the Grid but it has few interesting properties on it's own. Geohash has a single hash code value, not a coordinate pair like the Grid. Arbitrary precision of coordinates and gradual loss of precising while removing characters from the end of the hash code could come in useful. This also results with places nearby presenting similar hash code prefix. This naturally leads to indexing the hashes, B-Tree would be ideal. The hash code itself is a base 32 encoded interleaved pair of binary indexes for coordinates. Pretty smart.</p>

<p> Honestly half way through this research I got bored with it and with making a roguelike anyway. If I'd follow through I'd probably go for a combination of Geohash, Grid and Hilbert Curve. Geohash would allow arbitrary sizes, allowing entire galaxy of meters. Grid is the simple partitioning algorithm and can be encoded directly in geohash and Hilbert Curve is a nice packing algorithm to order grid cells and save on disk to be streamed to memory later.</p>

<p> I am really happy I did this research, I've learned a decent chunk of algorithms and data structures and feel much more confident now about my understanding how games organise space and implement open worlds.</p>

<h4>Tue Feb  4 00:58:57 CET 2020</h4>

<p> Another quick update. I just felt inspired and decided to add html template to my blog so I can make shorter lines and longer line spacing. Looks much better now! Also fixed the post ordering so post 10 doesn't show immidiately after post 1 but rather after post 1. And reversed the order so the latest post is at the top.</p>

<p> P.S. still worknig on that entry about spatial partitioning.</p>

<h4>Sun Feb  2 11:15:42 CET 2020</h4>

<p> A quick update. I'm currently ill with the seasonal virus and flu and have a bit more time. I've made small updates to my blog engine (fixed entry length to from 15 lines to infinite and improved handling of <code>_emphasis_</code> text). Since few days I'm working on a longer post about infinite game worlds and space partitioning, it should be out next week. Meantime something else I feel I need to share.</p>

<p> Yesterday I've discovered a fascinating and profound talk by Alan Kay https://www.youtube.com/watch?v=j9ZGFaIHegE. (Here is the pre-read https://internetat50.com/references/Kay_How.pdf.) Alan Kay has been working in ARPA and Xerox research facilities and had a lot to do with invention of only such small technologies as personal computers, graphical user interfaces, object oriented programing and the internet. If Alan Turing is the Newton of Computer Science, Alan Kay is the Einstein (he also looks like one in the video). It's amazing how profound that talk is. Every single minute hits home and has deep meaning. It almost feel like everything I've been studying over the last year has been in preparation to receive this talk. Whenever I feel I learn something profound and deeply meaningful I feel pleasurable feeling of excitement, a wave of tingling passes through my body. This was definitely one of those times. It could be the confirmation bias, but it felt great to know that my instinctive curiosity is leading me to the areas such great minds as Alan Kay are dwelling.</p>

<h4>Paying And Incuring Debts - Tue Jan 14 19:44:18 CET 2020</h4>

<p> My hackathon project turned out to be a grand success and turned out exactly the way I anticipated. Actually no, it surprised me how fast things have started moving and how far the cascading effects reached into areas I did not at all had foreseen in the most wonderful way. I believe my work has brought joy and promise of better future to many people, including myself. Currently I'm again resting from deeper dives into technology. I'll need to pay my debt and follow up on that hackathon migration success with similar successes for many other features in our monolith application. I've been whining all year about what I wanted. Now I got it and it's time to shut up and pay back the favour.</p>

<p> I'm using the downtime to decompress, refocus more on my personal mental and physical wellness. "Health" would have sounded wrong here since I do consider myself quite healthy at the moment, certainly not any less healthy then an average person of my circumstances. I focused on eating less and better things, I'm shyly trying my way back to some exercising and spending more time reading Nassim Taleb and Nietzsche. I also rediscovered the amazing joy of doing something selfless. Indeed Taleb is right about the Skin In The Game. But having skin in the game for a selfless cause feels almost ubermensch-ish... It definitely let me straighten up my back, rise my head and feel like I have right to be on this planet. But again it's critical I follow this promise of selflessness through and pay the debts. Not because how others see me. Because how I see myself.</p>

<p> PS. I noticed my posts are getting longer and less frequent. That was not the initial intention for this blog. I wanted to keep it more as a research log. I'll observe how it evolves for a while and then decide what to do about it.</p>

<h4>Sun Dec 22 21:46:17 CET 2019</h4>

<p> Recently I've been thinking more about computer graphics. Specifically about the 3D projection matrix and the occlusion culling techniques (based on BSP and octrees). I just found this awesome website with exhaustive and well explained 3D fundamentals https://www.scratchapixel.com/ (no occlusion culling though). </p>

<p> Did I mention I'd love to make a living owning a bike repair shop while making indie games? I don't have a thing for bikes, but they represent to me a different, slower kind of life. I'm 28 and even though I get bored with games much faster now and usually have enough after a one hour play session I still have in me 2 consecutive three hour play sessions every now and then. Not to mention how much actual time I spend consuming gaming content on youtube and the web (I should read more https://www.gamasutra.com/ though). I believe games are my biggest passion in life. There is something about the immersive escapism and world building that truly appeals to me.</p>

<h4>Sun Dec 15 20:33:26 CET 2019</h4>

<p> I've been busy with the hackathon held by my employer for the last few days so I couldn't really spend any time on personal projects. I managed to prepare PoC that it is possible to separate one of the major functionalities in our project into a separate project. This will decouple two teams and let each team has their own repository. I don't think I have to explain how far reaching positive effects this may have. It's a big win for me, my team, the other team and company in general. I hope I can follow up on this project afterwards and make the PoC into reality. Anyhow I feel pretty tired and bored with programming at the moment. Especially writing POSIX compliant scripts using sh, find, grep, sed and awk is quite difficult. I find POSIX versions of those utilities are really bare bones and often lack quality of life features. You can usually substitute those lacking features with just more scripts but in the heat of the moment like during a hackathon this can mean life or death. I imagine if I'd strictly stick with POSIX I'd build up a library of those convenience functions, but it will take time.</p>

<h4>Tue Dec 10 23:31:16 CET 2019</h4>

<p> I added awk pages to the blog. Right now this page is generated from multiple .md files concatonated by one <code>index.awk</code> file and all of it outputs as single <code>index.md</code>. I also added simple templating system.</p>

<h4>Mon Dec  9 22:39:51 CET 2019</h4>

<p> I've solve it! I have now variables working in blog tech. Apparently my problem was that xargs was treating everything as one big argument instead of few separate arguments separated -v. I think internally xargs is not calling shell but rather forks the program directly and passes arguments to it via the c interface. That would explain why the command that was generated by <code>xargs -t</code> was working correctly when manually copied and pasted into the terminal but would fail when run via xargs/make. Anyway next problem to solve in blog tech is start dynamically replace variable names from .md files into their values that were passed as arugments to awk script.</p>

<h4>Mon Dec  9 19:49:35 CET 2019</h4>

<p> I'm a little tired of <code>make</code> and <code>awk</code> at the moment so I decided to switch projects for a while. I have the template variables feature pretty much working except that for some reason when running <code>awk</code> via <code>make</code> it errors with <code>awk: invalid -v option</code> but that same exact command when run manually by pasting it in the terminal work sperfectly fine. I've recently heard that the "health" niche is evergreen on mobile. For the last year on and off I've been working on week organiser algorithm I named GYST. I'll brush up on this project. Update all the dependencies and see if I can make some progress. Last time I stopped at having simple D3 visualisation for my genetic algorithm since I needed to understand better why doesn't my algorithm work.</p>

<h4>Wed Dec  4 23:49:47 CET 2019</h4>

<p> No time for updates. That unfortunately means no serious progress in the blog tech. I only improved the <code>make deploy</code> so that it commit file delete changes. It had a bug where it would commit previous file again even if it was deleted in the new version.</p>

<h4>Hello world - Wed Dec  4 00:49:05 CET 2019</h4>

<p> This is the first entry. I made today significant progress with my blog tech.</p>

<ul>
<li><code>make deploy</code> prepares a new <code>gh-pages</code> branch commit and pushes it to github</li>
<li><code>awk/lib.awk</code> will be a common place for all shared awk functions</li>
<li><code>make build</code> supports now parsing markdown meta variables (disabled until useful)</li>
<li><code>make test</code> runs <code>make build</code> and automatically opens the browser. Super convenient especially when running <code>:!make test</code> in vim.</li>
</ul>

<p> I'm very happy with this but it's 1am and I really need to get some rest.   </body> </html></p>

